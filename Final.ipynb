{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ea9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import variance\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import johnson_lindenstrauss_min_dim\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.metrics import r2_score\n",
    "from prettytable import PrettyTable\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bad3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(X):\n",
    "    \n",
    "    #dropping id\n",
    "    id = X['ID']\n",
    "    X = X.drop(columns = ['ID'])\n",
    "    \n",
    "    #Removing Outliers\n",
    "    #X = X.drop(X[data['y'] > 155].index).reset_index(drop = True)\n",
    "    \n",
    "    #Removing 'X4' due to Low Variance\n",
    "    X = X.drop(columns = ['X4'])\n",
    "    \n",
    "    #Removing Features with Zero and Same Variance\n",
    "    \n",
    "    #Code\n",
    "    \n",
    "#     binary_features = X.drop(columns = ['ID', 'X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8'])\n",
    "#     clm_lst = list(binary_features.columns)\n",
    "\n",
    "#     var_lst = []\n",
    "#     for ele in clm_lst:\n",
    "#         var_lst.append(variance(binary_features[ele]))\n",
    "    \n",
    "#     var_df = pd.DataFrame()\n",
    "#     var_df['feature'] = clm_lst\n",
    "#     var_df['variance'] = var_lst\n",
    "    \n",
    "#     ftr_zero_var = []\n",
    "#     for i in range(var_df.shape[0]):\n",
    "#         if var_df['variance'][i] == 0:\n",
    "#             ftr_zero_var.append(var_df['feature'][i])\n",
    "            \n",
    "#     index_zero_var = var_df.index[var_df['variance'] == 0].tolist()\n",
    "#     var_df_upd = var_df.drop(index_zero_var, axis = 0).reset_index(drop = True)\n",
    "\n",
    "#     ftr_same_var = []\n",
    "#     for i in range(var_df_upd.shape[0]):\n",
    "#         for j in range(var_df_upd.shape[0]):\n",
    "#             if var_df_upd['feature'][i] == var_df_upd['feature'][j]:\n",
    "#                 continue\n",
    "#             elif var_df_upd['variance'][i] == var_df_upd['variance'][j]:\n",
    "#                 if var_df_upd['feature'][i] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(var_df_upd['feature'][i])\n",
    "#                 elif var_df_upd['feature'][j] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(var_df_upd['feature'][j])\n",
    "#             else:\n",
    "#                 continue\n",
    "    \n",
    "#     X = X.drop(columns = ftr_zero_var + ftr_same_var)\n",
    "    \n",
    "    feature_zero_var = joblib.load('FeatureZeroVar.pkl')\n",
    "    feature_same_var = joblib.load('FeatureSameVar.pkl')\n",
    "    \n",
    "    X = X.drop(columns = feature_zero_var + feature_same_var)\n",
    "    \n",
    "    #Encoding Categorical Features\n",
    "    \n",
    "    def encoding_categorical(data):\n",
    "        le = LabelEncoder()\n",
    "        data_le = le.fit_transform(data)\n",
    "        return data_le\n",
    "    \n",
    "    categorical_features = ['X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8']\n",
    "    catg = X[categorical_features]\n",
    "    \n",
    "    catg_encoded = pd.DataFrame()\n",
    "\n",
    "    for feature in categorical_features:\n",
    "        catg_encoded[feature] = encoding_categorical(catg[feature])\n",
    "        \n",
    "    #PCA\n",
    "    \n",
    "    binary = X.drop(columns = ['X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8'])\n",
    "    \n",
    "#     pca = PCA()\n",
    "#     pca.fit(binary)\n",
    "#     plt.plot(pca.explained_variance_ratio_.cumsum())\n",
    "#     plt.xlabel('number of components')\n",
    "#     plt.ylabel('cumulative explained variance')\n",
    "    \n",
    "    pca = joblib.load('PCA.pkl')\n",
    "    pca_binary = pca.transform(binary)\n",
    "    pca_binary_df = pd.DataFrame (pca_binary)\n",
    "    pca_binary_df = pca_binary_df[range(0, 100)]\n",
    "    \n",
    "    #SVD\n",
    "    \n",
    "#     svd = TruncatedSVD(n_components = 157)\n",
    "#     svd.fit(binary)\n",
    "#     plt.plot(svd.explained_variance_ratio_.cumsum())\n",
    "#     plt.xlabel('number of components')\n",
    "#     plt.ylabel('cumulative explained variance')\n",
    "    \n",
    "    svd = joblib.load('SVD.pkl')\n",
    "    svd_binary = svd.transform(binary)\n",
    "    svd_binary_df = pd.DataFrame (svd_binary)\n",
    "    svd_binary_df = svd_binary_df[range(0, 100)]\n",
    "    \n",
    "    #GRP\n",
    "    \n",
    "#     n_components = johnson_lindenstrauss_min_dim(n_samples = 4201, eps = 0.9)\n",
    "#     grp = GaussianRandomProjection(n_components = 206, random_state = 42)\n",
    "#     grp.fit(binary)\n",
    "    \n",
    "    grp = joblib.load('GRP.pkl')\n",
    "    grp_binary = grp.transform(binary)\n",
    "    grp_binary_df = pd.DataFrame (grp_binary)\n",
    "    \n",
    "    #Interaction\n",
    "    \n",
    "#     pf = PolynomialFeatures(interaction_only = True)\n",
    "#     pf.fit(binary)\n",
    "#     pf_binary = pf.transform(binary)\n",
    "#     pf_binary_df = pd.DataFrame(pf_binary)\n",
    "    \n",
    "#     #Top 10 Interaction Features\n",
    "    \n",
    "#     pf_var = []\n",
    "#     for feature in pf_binary_df.columns:\n",
    "#         pf_var.append(variance(pf_binary_df[feature]))     \n",
    "#     pf_ftr = list(pf_binary_df.columns)\n",
    "#     ftr_var_dict = {pf_ftr[i]: pf_var[i] for i in range(len(pf_var))}\n",
    "    \n",
    "#     pf_ftr_var_df = pd.DataFrame()\n",
    "#     pf_ftr_var_df['feature'] = pf_binary_df.columns\n",
    "#     pf_ftr_var_df['variance'] = pf_var\n",
    "    \n",
    "#     ftr_zero_var = []\n",
    "#     for i in range(pf_ftr_var_df.shape[0]):\n",
    "#         if pf_ftr_var_df['variance'][i] == 0:\n",
    "#             ftr_zero_var.append(pf_ftr_var_df['feature'][i])\n",
    "            \n",
    "#     index_zero_var = pf_ftr_var_df.index[pf_ftr_var_df['variance'] == 0].tolist()\n",
    "#     pf_ftr_var_df_upd = pf_ftr_var_df.drop(index_zero_var, axis = 0).reset_index(drop = True)\n",
    "    \n",
    "#     ftr_same_var = []\n",
    "#     for i in range(pf_ftr_var_df_upd.shape[0]):\n",
    "#         for j in range(pf_ftr_var_df_upd.shape[0]):\n",
    "#             if pf_ftr_var_df_upd['feature'][i] == pf_ftr_var_df_upd['feature'][j]:\n",
    "#                 continue\n",
    "#             elif pf_ftr_var_df_upd['variance'][i] == pf_ftr_var_df_upd['variance'][j]:\n",
    "#                 if pf_ftr_var_df_upd['feature'][i] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(pf_ftr_var_df_upd['feature'][i])\n",
    "#                 elif pf_ftr_var_df_upd['feature'][j] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(pf_ftr_var_df_upd['feature'][j])\n",
    "#             else:\n",
    "#                 continue\n",
    "                \n",
    "#     ftr_to_drop = ftr_zero_var + ftr_same_var\n",
    "#     final_pf_binary_df = pf_binary_df.drop(columns = ftr_to_drop)\n",
    "    \n",
    "#     pf_var_new = []\n",
    "#     for feature in final_pf_train_binary_df.columns:\n",
    "#         pf_var_new.append(variance(final_pf_train_binary_df[feature]))\n",
    "        \n",
    "#     pf_ftr_var_df_new = pd.DataFrame()\n",
    "#     pf_ftr_var_df_new['feature'] = final_pf_binary_df.columns\n",
    "#     pf_ftr_var_df_new['variance'] = pf_var_new\n",
    "    \n",
    "#     pf_ftr = list(final_pf_binary_df.columns)\n",
    "#     ftr_var_dict = {pf_ftr[i]: pf_var_new[i] for i in range(len(pf_var_new))}\n",
    "#     sorted_ftr_var_dict = dict( sorted(ftr_var_dict.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    \n",
    "    pf = joblib.load('PF.pkl')\n",
    "    pf_binary = pf.transform(binary)\n",
    "    pf_binary_df = pd.DataFrame(pf_binary)\n",
    "    top_10_interaction_features = [12526, 6639, 4899, 3178, 2437, 2483, 6181, 2811, 6854, 4573]\n",
    "    pf_binary_df = pf_binary_df[top_10_interaction_features]\n",
    "    \n",
    "    #Creating dataframes for model with original and new Features\n",
    "    \n",
    "    original = pd.concat([catg_encoded, X.drop(columns = ['X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8'])], axis = 1, join = 'inner')\n",
    "    original_all = pd.concat([original, pca_binary_df, svd_binary_df, grp_binary_df, pf_binary_df], axis = 1, join = 'inner')\n",
    "    \n",
    "    #Model\n",
    "    \n",
    "    dtr = joblib.load('DTR.pkl')\n",
    "    rfr = joblib.load('RandomForestRegressor.pkl')\n",
    "    \n",
    "    pred_dtr = dtr.predict(original)\n",
    "    pred_rfr = rfr.predict(original_all)\n",
    "    \n",
    "    pred = (pred_dtr + pred_rfr)/2\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d696b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(X, y):\n",
    "    \n",
    "    #dropping id\n",
    "    id = X['ID']\n",
    "    X = X.drop(columns = ['ID'])\n",
    "    \n",
    "    #Removing Outliers\n",
    "    #X = X.drop(X[data['y'] > 155].index).reset_index(drop = True)\n",
    "    \n",
    "    #Removing 'X4' due to Low Variance\n",
    "    X = X.drop(columns = ['X4'])\n",
    "    \n",
    "    #Removing Features with Zero and Same Variance\n",
    "    \n",
    "    #Code\n",
    "    \n",
    "#     binary_features = X.drop(columns = ['ID', 'X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8'])\n",
    "#     clm_lst = list(binary_features.columns)\n",
    "\n",
    "#     var_lst = []\n",
    "#     for ele in clm_lst:\n",
    "#         var_lst.append(variance(binary_features[ele]))\n",
    "    \n",
    "#     var_df = pd.DataFrame()\n",
    "#     var_df['feature'] = clm_lst\n",
    "#     var_df['variance'] = var_lst\n",
    "    \n",
    "#     ftr_zero_var = []\n",
    "#     for i in range(var_df.shape[0]):\n",
    "#         if var_df['variance'][i] == 0:\n",
    "#             ftr_zero_var.append(var_df['feature'][i])\n",
    "            \n",
    "#     index_zero_var = var_df.index[var_df['variance'] == 0].tolist()\n",
    "#     var_df_upd = var_df.drop(index_zero_var, axis = 0).reset_index(drop = True)\n",
    "\n",
    "#     ftr_same_var = []\n",
    "#     for i in range(var_df_upd.shape[0]):\n",
    "#         for j in range(var_df_upd.shape[0]):\n",
    "#             if var_df_upd['feature'][i] == var_df_upd['feature'][j]:\n",
    "#                 continue\n",
    "#             elif var_df_upd['variance'][i] == var_df_upd['variance'][j]:\n",
    "#                 if var_df_upd['feature'][i] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(var_df_upd['feature'][i])\n",
    "#                 elif var_df_upd['feature'][j] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(var_df_upd['feature'][j])\n",
    "#             else:\n",
    "#                 continue\n",
    "    \n",
    "#     X = X.drop(columns = ftr_zero_var + ftr_same_var)\n",
    "    \n",
    "    feature_zero_var = joblib.load('FeatureZeroVar.pkl')\n",
    "    feature_same_var = joblib.load('FeatureSameVar.pkl')\n",
    "    \n",
    "    X = X.drop(columns = feature_zero_var + feature_same_var)\n",
    "    \n",
    "    #Encoding Categorical Features\n",
    "    \n",
    "    def encoding_categorical(data):\n",
    "        le = LabelEncoder()\n",
    "        data_le = le.fit_transform(data)\n",
    "        return data_le\n",
    "    \n",
    "    categorical_features = ['X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8']\n",
    "    catg = X[categorical_features]\n",
    "    \n",
    "    catg_encoded = pd.DataFrame()\n",
    "\n",
    "    for feature in categorical_features:\n",
    "        catg_encoded[feature] = encoding_categorical(catg[feature])\n",
    "        \n",
    "    #PCA\n",
    "    \n",
    "    binary = X.drop(columns = ['X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8'])\n",
    "    \n",
    "#     pca = PCA()\n",
    "#     pca.fit(binary)\n",
    "#     plt.plot(pca.explained_variance_ratio_.cumsum())\n",
    "#     plt.xlabel('number of components')\n",
    "#     plt.ylabel('cumulative explained variance')\n",
    "    \n",
    "    pca = joblib.load('PCA.pkl')\n",
    "    pca_binary = pca.transform(binary)\n",
    "    pca_binary_df = pd.DataFrame (pca_binary)\n",
    "    pca_binary_df = pca_binary_df[range(0, 100)]\n",
    "    \n",
    "    #SVD\n",
    "    \n",
    "#     svd = TruncatedSVD(n_components = 157)\n",
    "#     svd.fit(binary)\n",
    "#     plt.plot(svd.explained_variance_ratio_.cumsum())\n",
    "#     plt.xlabel('number of components')\n",
    "#     plt.ylabel('cumulative explained variance')\n",
    "    \n",
    "    svd = joblib.load('SVD.pkl')\n",
    "    svd_binary = svd.transform(binary)\n",
    "    svd_binary_df = pd.DataFrame (svd_binary)\n",
    "    svd_binary_df = svd_binary_df[range(0, 100)]\n",
    "    \n",
    "    #GRP\n",
    "    \n",
    "#     n_components = johnson_lindenstrauss_min_dim(n_samples = 4201, eps = 0.9)\n",
    "#     grp = GaussianRandomProjection(n_components = 206, random_state = 42)\n",
    "#     grp.fit(binary)\n",
    "    \n",
    "    grp = joblib.load('GRP.pkl')\n",
    "    grp_binary = grp.transform(binary)\n",
    "    grp_binary_df = pd.DataFrame (grp_binary)\n",
    "    \n",
    "    #Interaction\n",
    "    \n",
    "#     pf = PolynomialFeatures(interaction_only = True)\n",
    "#     pf.fit(binary)\n",
    "#     pf_binary = pf.transform(binary)\n",
    "#     pf_binary_df = pd.DataFrame(pf_binary)\n",
    "    \n",
    "#     #Top 10 Interaction Features\n",
    "    \n",
    "#     pf_var = []\n",
    "#     for feature in pf_binary_df.columns:\n",
    "#         pf_var.append(variance(pf_binary_df[feature]))     \n",
    "#     pf_ftr = list(pf_binary_df.columns)\n",
    "#     ftr_var_dict = {pf_ftr[i]: pf_var[i] for i in range(len(pf_var))}\n",
    "    \n",
    "#     pf_ftr_var_df = pd.DataFrame()\n",
    "#     pf_ftr_var_df['feature'] = pf_binary_df.columns\n",
    "#     pf_ftr_var_df['variance'] = pf_var\n",
    "    \n",
    "#     ftr_zero_var = []\n",
    "#     for i in range(pf_ftr_var_df.shape[0]):\n",
    "#         if pf_ftr_var_df['variance'][i] == 0:\n",
    "#             ftr_zero_var.append(pf_ftr_var_df['feature'][i])\n",
    "            \n",
    "#     index_zero_var = pf_ftr_var_df.index[pf_ftr_var_df['variance'] == 0].tolist()\n",
    "#     pf_ftr_var_df_upd = pf_ftr_var_df.drop(index_zero_var, axis = 0).reset_index(drop = True)\n",
    "    \n",
    "#     ftr_same_var = []\n",
    "#     for i in range(pf_ftr_var_df_upd.shape[0]):\n",
    "#         for j in range(pf_ftr_var_df_upd.shape[0]):\n",
    "#             if pf_ftr_var_df_upd['feature'][i] == pf_ftr_var_df_upd['feature'][j]:\n",
    "#                 continue\n",
    "#             elif pf_ftr_var_df_upd['variance'][i] == pf_ftr_var_df_upd['variance'][j]:\n",
    "#                 if pf_ftr_var_df_upd['feature'][i] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(pf_ftr_var_df_upd['feature'][i])\n",
    "#                 elif pf_ftr_var_df_upd['feature'][j] not in ftr_same_var:\n",
    "#                     ftr_same_var.append(pf_ftr_var_df_upd['feature'][j])\n",
    "#             else:\n",
    "#                 continue\n",
    "                \n",
    "#     ftr_to_drop = ftr_zero_var + ftr_same_var\n",
    "#     final_pf_binary_df = pf_binary_df.drop(columns = ftr_to_drop)\n",
    "    \n",
    "#     pf_var_new = []\n",
    "#     for feature in final_pf_train_binary_df.columns:\n",
    "#         pf_var_new.append(variance(final_pf_train_binary_df[feature]))\n",
    "        \n",
    "#     pf_ftr_var_df_new = pd.DataFrame()\n",
    "#     pf_ftr_var_df_new['feature'] = final_pf_binary_df.columns\n",
    "#     pf_ftr_var_df_new['variance'] = pf_var_new\n",
    "    \n",
    "#     pf_ftr = list(final_pf_binary_df.columns)\n",
    "#     ftr_var_dict = {pf_ftr[i]: pf_var_new[i] for i in range(len(pf_var_new))}\n",
    "#     sorted_ftr_var_dict = dict( sorted(ftr_var_dict.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    \n",
    "    pf = joblib.load('PF.pkl')\n",
    "    pf_binary = pf.transform(binary)\n",
    "    pf_binary_df = pd.DataFrame(pf_binary)\n",
    "    top_10_interaction_features = [12526, 6639, 4899, 3178, 2437, 2483, 6181, 2811, 6854, 4573]\n",
    "    pf_binary_df = pf_binary_df[top_10_interaction_features]\n",
    "    \n",
    "    #Creating dataframes for model with original and new Features\n",
    "    \n",
    "    original = pd.concat([catg_encoded, X.drop(columns = ['X0', 'X1', 'X2', 'X3', 'X5', 'X6', 'X8'])], axis = 1, join = 'inner')\n",
    "    original_all = pd.concat([original, pca_binary_df, svd_binary_df, grp_binary_df, pf_binary_df], axis = 1, join = 'inner')\n",
    "    \n",
    "    #Model\n",
    "    \n",
    "#     x_train_org, x_cv_org, y_train_org, y_cv_org = train_test_split(original, y, test_size = 0.2, random_state = 42)\n",
    "#     x_train_all, x_cv_all, y_train_all, y_cv_all = train_test_split(original_all, y, test_size = 0.2, random_state = 42)\n",
    "      \n",
    "#     dtr = DecisionTreeRegressor(max_depth = 5)\n",
    "#     dtr.fit(x_train_org, y_train_org)\n",
    "\n",
    "#     rfr = RandomForestRegressor(n_estimators = 500, max_features = 'auto', max_depth = 3, min_samples_leaf = 1, min_samples_split = 10)\n",
    "#     rfr.fit(x_train_all, y_train_all)\n",
    "    \n",
    "    x_train_org, x_cv_org, y_train_org, y_cv_org = train_test_split(original, y, test_size = 0.2, random_state = 42)\n",
    "    x_train_all, x_cv_all, y_train_all, y_cv_all = train_test_split(original_all, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    \n",
    "    dtr = joblib.load('DTR.pkl')\n",
    "    rfr = joblib.load('RandomForestRegressor.pkl')\n",
    "    \n",
    "    pred_dtr = dtr.predict(x_cv_org)\n",
    "    pred_rfr = rfr.predict(x_cv_all)\n",
    "    \n",
    "    pred = (pred_dtr + pred_rfr)/2\n",
    "    \n",
    "    r2 = r2_score(y_cv_all, pred)\n",
    "    \n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8fd97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "y = train['y']\n",
    "train = train.drop(columns = ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18053944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 77.51600352, 112.39332834,  78.19243321, ...,  93.94086633,\n",
       "       112.65364148,  93.94086633])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fun_1(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7338df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.610665245992309"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_fun_2(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ca72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
